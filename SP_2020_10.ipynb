{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNDS6013 Scientific Python: 10th Class\n",
    "## Central European University, Winter 2019/2020\n",
    "\n",
    "Instructor: Márton Pósfai, TA: Luis Natera Orozco\n",
    "\n",
    "Emails: posfaim@ceu.edu, natera_luis@phd.ceu.edu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go though this notebook and\n",
    "* Follow links to videos explaining some basics of the XML and HTML file formats\n",
    "* Study the example codes\n",
    "* Solve the exercises in the notebook. Try looking at solutions only when you are done.\n",
    "* Complete a final task and upload only the resulting figure to Moodle in pdf format, do not upload your code.\n",
    "\n",
    "If you have any questions or you get stuck with one of the exercises I will be available on the [slack channel](http://sp2020winter.slack.com). I will be online during regular class hours, outside of that I will try to get back to you as soon as possible.\n",
    "\n",
    "\n",
    "## Today\n",
    "\n",
    "Many of your final project proposals include scraping data from online sources. To give you a powerful tool for this, we will learn how to use `BeautifulSoup` to parse and search websites and XML files. We use these tools to plot the change of the human population over history using data obtained from Wikipedia.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Watch video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=0ba489d3-a006-4e9d-adf1-ab8200ccdb32).\n",
    "\n",
    "XML stands for Extendable Markup language.\n",
    "* A universal purpose markup language\n",
    "* Both human and computer readable\n",
    "* Represents information in a hierarchical way\n",
    "* Strict syntax rules → effective and unambiguous parsing\n",
    "* Stored in plain text\n",
    "* Many API use it for communication\n",
    "* Many file formats are special cases of XML:\n",
    "    * SVG: Scalable Vector Graphics\n",
    "    * RSS feeds\n",
    "    * Microsoft Word docx\n",
    "\n",
    "Let's take a look at an example (for further details see slides):\n",
    "\n",
    "```xml\n",
    "<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n",
    "<breakfast_menu tasty=\"True\">\n",
    "  <food kind=\"vegan\">\n",
    "    <item>Belgian Waffles</item>\n",
    "    <price>$5.95</price>\n",
    "    <description>Two of our famous...</description>\n",
    "    <calories>650</calories>\n",
    "  </food>\n",
    "  <food>\n",
    "    <item>French Toast</item>\n",
    "    <price>$4.50</price>\n",
    "    <description>Thick slices made...</description>\n",
    "    <calories>600</calories>\n",
    "  </food>\n",
    "  <food>\n",
    "    <item>Homestyle Breakfast</item>\n",
    "    <price>$6.95</price>\n",
    "    <description>Two eggs, bacon...</description>\n",
    "    <calories>950</calories>\n",
    "  </food>\n",
    "</breakfast_menu>\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An XML parser can help you navigate and manipulate the XML tree. We will use the module [BeautifulSoup](https://www.crummy.com/software/BeautifulSoup/bs4/doc/), technically it is built on top of a lower level parser with many useful functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "with open(\"test.xml\",encoding='utf-8') as f:\n",
    "    #from the file we create a soup object\n",
    "    #we also specify the parser it uses as \"xml\", later we will use BeautifulSoup to parse html files too\n",
    "    soup = BeautifulSoup(f,\"xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tags and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#access child by name\n",
    "print(type(soup.breakfast_menu))\n",
    "print()\n",
    "\n",
    "#get name of the tag\n",
    "print(soup.breakfast_menu.name)\n",
    "print()\n",
    "\n",
    "#get attributes of a tag as a dictionary\n",
    "print(soup.breakfast_menu['tasty'])\n",
    "print()\n",
    "\n",
    "#if multiple children with the same tag, we get the first one\n",
    "#text: all text, including text contained by offspring\n",
    "print(soup.breakfast_menu.food)\n",
    "print()\n",
    "\n",
    "#string: only the text directly inside tag\n",
    "print(soup.breakfast_menu.food.item.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also change things, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup.breakfast_menu.food.item.string)\n",
    "soup.breakfast_menu.food.item.string = \"Yummy Belgian Waffles\"\n",
    "print(soup.breakfast_menu.food.item.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Navigating the tree\n",
    "* Moving down: iterate through the children of a tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the first food on the menu\n",
    "food1 = soup.breakfast_menu.food\n",
    "\n",
    "list_of_children = list(food1.children)\n",
    "print(list_of_children)\n",
    "print()\n",
    "\n",
    "#children also include strings containing end of line characters, to exclude them\n",
    "for child in food1.children:\n",
    "    if child != '\\n':\n",
    "        print(child)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Moving up: get the parent of a tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(food1.parent.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* You can also move sideways: check documentation for `next_siblings` and `previous_siblings`\n",
    "\n",
    "## Searching\n",
    "\n",
    "Most often instead of navigating up and down the tree we search for tags that match some requirements. For this we can use:\n",
    "* Find the first match: `soup.find()`\n",
    "* Find all matches: `soup.find_all()`\n",
    "\n",
    "We can specify what we are searching for in various ways:\n",
    "* Search based on tag names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for food in soup.find_all(\"food\"):\n",
    "    print(food.item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Search based on attributes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for vegan_stuff in soup.find_all(kind=\"vegan\"):\n",
    "    print(vegan_stuff.item.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can even use functions! This is a powerful tool that allows for very complex searches. For example, we can look for food options that have waffles in their description:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function takes a tag as input\n",
    "#outputs True if it's a match, False if it's not\n",
    "def match(tag):\n",
    "    if tag.name==\"food\": #check if it is a food\n",
    "        if \"waffles\" in tag.text: #check if waffles are mentioned \n",
    "            return True\n",
    "    #if we didn't return True, we return False\n",
    "    return False\n",
    "\n",
    "for waffles in soup.find_all(match):\n",
    "    print(waffles.item.string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Or we can do the same thing using lambda functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for waffles in soup.find_all(lambda tag: tag.name==\"food\" and \"waffles\" in tag.text):\n",
    "    print(waffles.item.string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Print out the price of all food items.\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "You are looking for the `<price>` tags, use the `soup.find_all()` function to get all matches.\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "for price in soup.find_all(\"price\"):\n",
    "    print(price.string)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Calculate the average calorie of the food options.\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "The calories are in string format, you have to convert them to a number using the `float()` function. If you store these numbers in a list, you can use `numpy`'s `np.mean()` function to get the average.\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "import numpy as np\n",
    "calories = [float(cal.string) for cal in soup.find_all(\"calories\")]\n",
    "print(\"%.2f\"%np.mean(calories))\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "Print out all food items that have less than 800 calories\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "This is a bit more tricky. You can define `match(tag)` function to use with `find_all()` as we did when we were searching for waffles. To get the calories withing the `mahtch(tag)` function use `tag.calories.string`.\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "def match(tag):\n",
    "    if tag.name==\"food\":\n",
    "        if float(tag.calories.string)<800:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "for food in soup.find_all(match):\n",
    "    print(food.item.string)\n",
    "\n",
    "#or with a lambda function\n",
    "for food in soup.find_all(lambda tag: tag.name==\"food\" and float(tag.calories.text)<800):\n",
    "    print(food.item.string)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "You are worried about global warming and you would like to encourage people to reduce their carbon footprint. Reduce the price of all vegan items by 10 percent!\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "In a previous example, we already searched for vegan items. Scroll back if you don't remember how.\n",
    "\n",
    "You can modify the string contained in a tag simply by overwriting it, e.g., `food.price.sting = new_price`.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "for food in soup.find_all(kind='vegan'):\n",
    "    #convert price to number\n",
    "    price = float(food.price.string[1:])\n",
    "    #calculate new price\n",
    "    new_price = .9*price\n",
    "    #convert new price to string\n",
    "    new_str = \"$%.2f\"%new_price\n",
    "    #update xml\n",
    "    food.price.string = new_str\n",
    "    \n",
    "#test\n",
    "for food in soup.find_all('food'):\n",
    "    print(food.item.string, food.price.string)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping by parsing HTML\n",
    "\n",
    "[Watch video.](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=276ebf77-45c6-464b-9ba4-ab8200e4194f)\n",
    "\n",
    "HTML stands for Hypertext Markup Language, it is a text file that describes how a website looks. When you open a website in your browser, it downloads the HTML file and translates it into what you see.\n",
    "\n",
    "You can view the HTML source code of a website by hitting ctrl-u (or Command+Option+u in Safari). For a simple example visit [this site](http://posfaim.web.elte.hu/example.html) and look at the source code.\n",
    "\n",
    "It looks very similar to an XML file, but there are some differences. Check out the additional slides and the next video for more details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `BeautifulSoup` to parse and search the website as we did with XML before! Let's open the website using the `urllib.request` module and create a soup object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "webpage = urllib.request.urlopen(\"http://posfaim.web.elte.hu/example.html\")\n",
    "soup = BeautifulSoup(webpage,\"lxml\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that we use a different parser, the HTML parser is confusingly called `\"lxml\"`.\n",
    "\n",
    "Now we can navigate and search the HTML tree. For example, we can access tags by their names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for example, we can access tags by their names\n",
    "title = soup.html.head.title.string\n",
    "print(title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can find the table and access the data in it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there is only one table on the webpage, so we can use the find() function\n",
    "#which returns the first match\n",
    "table = soup.find(\"table\") \n",
    "\n",
    "for row in table.find_all(\"tr\")[1:]: #iterate through the rows of the table, we skip the header\n",
    "    animal = row.th.string.strip().lower() #get the row headers, and make the string look prettier\n",
    "    \n",
    "    cells = row.find_all(\"td\") # get all cells in the row\n",
    "    legs = cells[2].string.strip() #grab the third one\n",
    "    print(\"The \"+animal+\" has \"+legs+\" legs.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Find all links on the page and print out all urls that they point to. If you forgot what tags represent links, look at the website's source code.\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "To access the attribute `att` of a tag use `tag['att']`.    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in soup.find_all(\"a\"):\n",
    "    print(a['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "for a in soup.find_all(\"a\"):\n",
    "    print(a['href'])\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## World population over time\n",
    "\n",
    "Now for some real webscraping. Our task is to plot the world population as a function of time based on this [table](https://en.wikipedia.org/wiki/World_population#Past_population) found on Wikipedia. Your first step is to investigate the source code of the website, you will find that it is more complex and longer than our first little example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Dowload the https://en.wikipedia.org/wiki/World_population webpage and create a soup object called `pop_soup`.\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "You can use the same code as we used to download the simple example website, you only have to change the URL.    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "webpage = urllib.request.urlopen(\"https://en.wikipedia.org/wiki/World_population\")\n",
    "pop_soup = BeautifulSoup(webpage,\"lxml\") \n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Watch video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=3d773823-6623-4da1-ac87-ab82012d0aa2)\n",
    "\n",
    "Open the source code of the website https://en.wikipedia.org/wiki/World_population in your browser. Let's try to figure out a way to find the `<table>` tag containing the \"Past population\" table.\n",
    "\n",
    "One possibility if to search for the pattern \"<table\" in your browser using `ctrl-f`, this will find and count the tables. Iterating throught them by hand, we can see that our table of interest is the 11th."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pop_soup.find_all(\"table\")[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another possibility is that we notice that this is the only table that has BC dates in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pop_soup.find(lambda tag: tag.name==\"table\" and \"BC\" in tag.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we used `tag.text`, remember `tag.string` is the text directly in the tag, `tag.text` is all the text stored in the tag, its children and other descedents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have the table, lets extract the year column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_list = []\n",
    "for row in table.find_all(\"tr\")[1:]: #we leave out the first row, because that is just a header\n",
    "    #the year is in the row headers\n",
    "    year_list.append(row.th.string)\n",
    "    \n",
    "print(year_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to use this for a plot, we have to convert these strings into numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_year_list = []\n",
    "for str_year in year_list:\n",
    "    #remove any commas\n",
    "    str_year = str_year.replace(\",\",\"\")\n",
    "    #remove AD\n",
    "    str_year = str_year.replace(\"AD\",\"\")\n",
    "    \n",
    "    #if the year is BC, remove BC and add a negative sign to the front\n",
    "    if \"BC\" in str_year:\n",
    "        str_year = \"-\"+str_year.replace(\"BC\",\"\")\n",
    "    \n",
    "    #convert it to a number\n",
    "    num_year_list.append(float(str_year))\n",
    "\n",
    "print(num_year_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Obtain a list `num_pop_list` containing the world population as a number. Treat \"<0.015\" as \"0.015\".\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "Do something similar as the previous example. Remove `,` and `<` characters and convert the string to a float. \n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "num_pop_list = []\n",
    "for row in table.find_all(\"tr\")[1:]: #we leave out the first row, because that is just a header\n",
    "    #the world population is the first column\n",
    "    #if we refer to the tag <td> by name, it returns the first instance\n",
    "    pop = row.td.string\n",
    "    #remove '<'\n",
    "    pop = pop.replace(\"<\",\"\")\n",
    "    #remove ','\n",
    "    pop = pop.replace(\",\",\"\")\n",
    "    num_pop_list.append(float(pop))\n",
    "    \n",
    "print(num_pop_list)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Plot the world population as a function of the year. The oldest datapoints are rough estimates, try excluding them.\n",
    "\n",
    "Bonus: Is the growth exponential? Try setting the y axis to log scale too! \n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "Import `matplotlib.pyplot` and use the `plot()` function. To set the y axis to logscale, you can use `plt.yscale(\"log\")`. To exclude the 3 oldest datapoints use `num_pop_list[3:]`.\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1,2,figsize=(14,5))\n",
    "plt.sca(axes[0])\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Population [million]\")\n",
    "plt.plot(num_year_list[3:],num_pop_list[3:],'o-')\n",
    "\n",
    "plt.sca(axes[1])\n",
    "plt.plot(num_year_list[3:],num_pop_list[3:],'o-g')\n",
    "plt.xlabel(\"Year\")\n",
    "plt.ylabel(\"Population [million]\")\n",
    "plt.yscale('log')\n",
    "plt.show()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving figures in pdfs\n",
    "\n",
    "Some of you had trouble saving your plots in pdf files. You can do this using the `plt.savefig(\"myfigure.pdf\")` function, the format of the file is decided based on the extension of the filename.\n",
    "\n",
    "A common pitfall is that you cannot use `plt.savefig(\"myfigure.pdf\")` after calling `plt.show()`. The reason for this that while you are plotting there is an active figure that matplotlib keeps track of in the background, when you call `plt.show()` clears the active figure, and `plt.savefig()` ends up saving an empty figure. To avoid this just run `plt.savefig()` first, or leave `plt.show()` out altogether. You can try this out using the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10))\n",
    "#plt.show()\n",
    "plt.savefig(\"myfigure.pdf\")\n",
    "#plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercise\n",
    "\n",
    "Pick **one** of the following problems and upload **only** the resulting figure as a pdf to Moodle. Successfully completing this task counts as attendance.\n",
    "1. Scrape and plot a table from Wikipedia, for example,\n",
    "    * [Voter turnout in US elections](https://en.wikipedia.org/wiki/Voter_turnout_in_the_United_States_presidential_elections)\n",
    "    * [The monthly average temperature for a city of your choice](https://en.wikipedia.org/wiki/List_of_cities_by_average_temperature)\n",
    "    * Anything else you find interesting <br><br>\n",
    "2. [RSS](https://en.wikipedia.org/wiki/RSS) (Really Simple Syndication) feeds publish updates of websites or other information in XML format. Download, parse and create a plot using one of the following feeds:\n",
    "    * Plot the maximum temperature forcasted for the next three days in [Budapest](https://weather-broker-cdn.api.bbci.co.uk/en/forecast/rss/3day/3054643)\n",
    "    * Create a bar chart showing the number of recent observations of Great Bustards (Túzok) and Peregrine Falcons (Vándorsólyom) in Hungary using the [feed of birding.hu](http://www.birding.hu/rss.php?rss=erdekes) *This feed is in Hungarian.*\n",
    "    * Find an interesting feed and plot something. To locate feeds look for the <img src=https://upload.wikimedia.org/wikipedia/en/thumb/4/43/Feed-icon.svg/256px-Feed-icon.svg.png style=\"width: 2%; display: inline\"> icon on websites."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
