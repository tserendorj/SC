{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNDS6013 Scientific Python: 12th Class\n",
    "## Central European University, Winter 2019/2020\n",
    "\n",
    "Instructor: Márton Pósfai, TA: Luis Natera Orozco\n",
    "\n",
    "Emails: posfaim@ceu.edu, natera_luis@phd.ceu.edu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the class, go though this notebook and\n",
    "* Study the example codes\n",
    "* Solve the exercises in the notebook. Try looking at solutions only when you are done.\n",
    "* Follow links to videos for short verbal explanations if needed\n",
    "* Complete a final task and upload your result to Moodle, pay attention to upload only **a single pdf figure, do not upload your code**.\n",
    "\n",
    "If you have any questions or you get stuck with one of the exercises I will be available on the [slack channel](http://sp2020winter.slack.com). I will be online during regular class hours, outside of that I will try to get back to you as soon as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "## Today's plan:\n",
    "\n",
    "We will continue our introduction to [pandas](http://pandas.pydata.org/):\n",
    "- Use pandas to analyze a bike sharing system\n",
    "- Use the datetime functionality of pandas\n",
    "- Do more plotting and take a brief look at the [seaborn](https://seaborn.pydata.org/) library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First: when to use which module?\n",
    "\n",
    "[Video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=fc70308b-26c8-4b0b-8fd5-ab8b00d12224)\n",
    "\n",
    "During this term, we learned about many python modules some of the have similar functionality, and we have seen that any given problem can be solved in multiple ways and with multiple tools. For example, to store data python has built in data structures like lists and dictionaries, numpy as n-dimensional arrays, and right now we are learning about pandas' series and dataframe, all of them have overlapping usage.\n",
    "\n",
    "So how to choose the best tool for your problem? There is of course no strict rule, but the main guidline that I recommend following is: use the simplest tool that allows you to concisely complete your task. Let's look at the question which datastructure to use:\n",
    "\n",
    "* **Lists, dictionaries:** These are our most simple options, use it for small common task such as passing parameters to a function, or when you are not planning to use special features of more complex modules. They are built in datatypes of python; therefore they don't introduce additional dependency and your code will be more portable.\n",
    "* **numpy arrays:** Numpy arrays are built for performance, they are the most useful when you have purely numeric data and you do intensive calculations with them. Applications include, but are not limited to, optimization problems, solving equations numerically, image processing, etc. Many additional modules rely on numpy, including pandas.\n",
    "* **pandas:** Use them if your data is spreadsheet-like, requires cleaning or merging. Also pandas makes many common tasks very easy, such as dealing with timestamps or simple data exploration and visualization (and other things we cover in class).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part III: Bikesharing with Pandas\n",
    "\n",
    "[Video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=fd4f3a1a-5b98-4a17-be01-ab8b00d637a2)\n",
    "\n",
    "Let's look at bike sharing data from Chicago. In Chicago there is a bike-sharing program just like Budapest's Bubi, called Divvy. We have two datasets (retrieved from https://www.divvybikes.com/system-data): one on trips and another on stations. We'll have to combine the two to explore how people use Divvy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trips = pd.read_csv('Divvy_Trips_2013.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many trips does our data set contain? In other words, how many rows are there in the dataframe?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trips.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic summary of data frame: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column meanings:\n",
    "- trip_id: trip identifier\n",
    "- starttime: time bike was rented\n",
    "- stoptime: time bike was returned\n",
    "- bikeid: bike identifier\n",
    "- trip duration: duration of the trip in seconds\n",
    "- from_station_id: station id from which bike was borrowed\n",
    "- from_station_name: station name from which bike was borrowed\n",
    "- to_station_id: station id to which bike was returned\n",
    "- to_station_name: sstation id to which bike was returned\n",
    "- usertype: Customer or subscribers. Customers are one time users that pay for single trips, subscribers buy a monthly -pass with unlimited rides.\n",
    "- gender: Gender, if known, of user\n",
    "- birthyear: year of birth, if known, of user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to continue with exploring the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heterogeneous trip durations\n",
    "\n",
    "[Video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=734d14b0-992c-41e9-bc16-ab8b00d76ffc)\n",
    "\n",
    "For example, let's plot the trip duration distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['tripduration'].plot(kind='hist',bins=50);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is not too helpful, we have a few trips that are much longer than average. \n",
    "Let's create a new column with the logarithm of the tripduration and plot that.\n",
    "\n",
    "We can use the `apply()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['logduration']=trips['tripduration'].apply(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or since `np.log()` is a numpy function, we can simply write:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['logduration']=np.log(trips['tripduration'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax=trips['logduration'].plot(kind='hist',bins=50,color='#9BCC31')\n",
    "ax.set_xlabel('Log(trip duration)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This looks better. What this means is that tripduration has a very wide distribution, which is closer to a lognormal than a normal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Most used bikes\n",
    "\n",
    "Let's see which bike is on the road the longest: perhaps a good candidate for early retirement. The `bikeid` column uniquely identifies the bikes, to find all trips associated to each bike we can use the `groupby()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_usage = trips.groupby('bikeid')['tripduration'].sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's unpack this line of code:\n",
    "1. `groupby(bikeid)`: this creates a group for each individual bike\n",
    "2. `['tripduration']`: pick the `tripduration` column\n",
    "3. `sum()`: sum all trips for each bike, so we get a series containing the total usage and indexed by the bike IDs\n",
    "4. `sort_values(ascending=False)`: sort in descending order so that the most used bike is in the first row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most used bikes are in the first rows, we can print out the top 10 using `head()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bike_usage.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The least used bikes are at the end:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_usage.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = bike_usage.hist(bins=40,color='g');\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_xlabel(\"total usage\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Repeat the previous analysis, but instead of the total duration of usage, look at the total number of times the bikes were used. Do you get the same bikes in the top 10?\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "    \n",
    "The only difference is that instead of using the `sum()` function to aggregate the data for each bike, we use the `count()` function, which simply counts the number of elements in the group. \n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "bike_usage2 = trips.groupby('bikeid')['tripduration'].count().sort_values(ascending=False)\n",
    "ax = bike_usage2.hist(bins=40,color='g');\n",
    "ax.set_ylabel(\"count\")\n",
    "ax.set_xlabel(\"total number of times used\");\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Timestamps\n",
    "\n",
    "[Video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=bc18a9de-d075-4d9f-9f7c-ab8b00d9ee84)\n",
    "\n",
    "We can use the timestamps associated to each trip to investigate such questions as how usage depends on the time of the year, day of the week or part of the day.\n",
    "\n",
    "How can we make use of these timestamps? First, let's see how the timestamps are currently stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(trips['starttime'][0])\n",
    "print(type(trips['starttime'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's turn those time columns into pandas' timestamp objects, which are similar to python's datetime objects. It is a common task so pandas has a built in function for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips.starttime = pd.to_datetime(trips.starttime, format=\"%Y-%m-%d %H:%M\")\n",
    "trips.stoptime = pd.to_datetime(trips.stoptime, format=\"%Y-%m-%d %H:%M\")\n",
    "\n",
    "print(trips['starttime'][0])\n",
    "print(type(trips['starttime'][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Side note: we can access a column by name two ways, `trips['starttime']` is the same as `trips.starttime`.)\n",
    "\n",
    "Note about `to_datetime()`: if you don't pass a format pandas will try to guess it. It does a decent job, but takes slower and is risky. One can also pass `errors = \"coerce\"` and it will return `NaT` (Not a Time) values for those entries that don't fit into the format you give."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use these columns to plot stuff. For example, let's see the variation in duration by start time across the year. Plotting as a function of time has never been easier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = trips.plot(kind='line', x='starttime', y='tripduration', figsize=(14,5));\n",
    "#trips.rolling('5D').mean().plot(kind='line', x='starttime', y='tripduration',ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a mess, let's try to instead look at daily averages. Currently the timestamps have minute precision, let's create a column that only contains the day. For this, we can use the `date` method of timestamp objects. As a demonstration let's apply it to the first timestamp in the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['starttime'][0].date()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a new column using `apply()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['startdate']=trips['starttime'].apply(lambda dt: dt.date())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we group by the date and calculate the average:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_tripduration = trips.groupby('startdate')['tripduration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now a series that is indexed by the date and contains the average trip duration for each day:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_tripduration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_avg_tripduration.plot(kind='line',figsize=(14,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see two patterns:\n",
    "* There is an overall decreasing trend: people go on shorter trips in the winter\n",
    "* Usage is periodic\n",
    "* Bonus question: can you guess why might we see that peak on the first day? (Hint: think of the shape of the distribution of the trip duration and sample sizes.)\n",
    "\n",
    "Let's investigate the origin of the periodicity! Perhaps it is a weekly pattern? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Repeat the previous analysis, but instead of doing a daily average for each day, calculate the average for the days of the week, i.e., you will get seven datapoints, the average trip duration for each day of the week.\n",
    "* Create a new column named `'dayofweek'` that contains the day of the week the trip started\n",
    "* Group the trips based on this new column\n",
    "* Plot the result\n",
    "\n",
    "What did you find?\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "To get the day of the week using the `dayofweek` attribute of timestamps. Pay attention: this is not a function, there is no parenthesis at the end. For example, the day of week of the first timestamp is `trips.['starttime'][0].weekofday`.\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips['dayofweek']=trips['starttime'].apply(lambda dt: dt.dayofweek)\n",
    "dayofweek_avg_tripduration = trips.groupby('dayofweek')['tripduration'].mean()\n",
    "dayofweek_avg_tripduration.plot(kind='line',figsize=(10,5));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "trips['dayofweek']=trips['starttime'].apply(lambda dt: dt.dayofweek)\n",
    "dayofweek_avg_tripduration = trips.groupby('dayofweek')['tripduration'].mean()\n",
    "dayofweek_avg_tripduration.plot(kind='line',figsize=(10,5));\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting with Seaborn\n",
    "\n",
    "Pandas plotting is simple but limited, matplotlib plotting is complicated but powerful. A library called [seaborn](https://seaborn.pydata.org/) is in the middle and it works very well with data in pandas. We will very briefly look at few things that we can do with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set_style('white')# you can try other styles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do women and men use Divvy the same way? Let's look at the previous plot, but separate it for the two groups. We can use `groupby()` to group according to two columns by passing a list containing the names of the column to `groupby()` (we did something similar with the Titanic dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek_gender_duration = trips.groupby(['dayofweek','gender'])['tripduration'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a series with hierarchical indices (`dayofweek` and `gender`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dayofweek_gender_duration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For plotting we will need a dataframe. We can use `reset_index()` to convert the indices to regular columns and index the rows with integers instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dayofweek_gender_duration = dayofweek_gender_duration.reset_index()\n",
    "dayofweek_gender_duration.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this is now a dataframe which is indexed by integers, and the previous indices became regular columns `dayofweek` and `gender`.\n",
    "\n",
    "We use seaborn to create a more fancy plot: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax=sns.pointplot(data=dayofweek_gender_duration,x='dayofweek',y='tripduration', hue='gender')\n",
    "ax.set_ylabel('Average duration of trips')\n",
    "ax.set_title('Average trip duration per day user gender');\n",
    "# Seaborn has a bunch of formatting options\n",
    "# e.g., despine removes top and right sides of the frame\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that men go on shorter duration trips, but their trip length increases more on weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "Our dataset also has a column named `usertype`, it differentiates between customer or subscribers. Customers are one time users that pay for single trips, subscribers buy a monthly -pass with unlimited rides.\n",
    "\n",
    "Do customers and subscribers behave differently? Repeat the above analysis for these categories. In addition to trip duration, compare total number of trips as well in a separate cell. What pattern do you see?\n",
    "\n",
    "<details><summary><u>Hint</u></summary>\n",
    "<p>\n",
    "\n",
    "You can do exatly the same as before only:\n",
    "* group by `usertype` instead of `gender`\n",
    "* also repeat your plot for `count()` instead of `mean()`\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "dayofweek_usertype_duration = trips.groupby(['dayofweek','usertype'])['tripduration'].mean().reset_index()\n",
    "ax=sns.pointplot(data=dayofweek_usertype_duration,x='dayofweek',y='tripduration', hue='usertype')\n",
    "ax.set_ylabel('Average duration of trips')\n",
    "ax.set_title('Average trip duration per day user type');\n",
    "sns.despine()\n",
    "\n",
    "dayofweek_usertype_duration = trips.groupby(['dayofweek','usertype'])['tripduration'].count().reset_index()\n",
    "ax=sns.pointplot(data=dayofweek_usertype_duration,x='dayofweek',y='tripduration', hue='usertype')\n",
    "ax.set_ylabel('Number of trips')\n",
    "ax.set_title('Number of trips per user type');\n",
    "sns.despine()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have to restrict ourselves to looking at the only at the daily average. Seaborn has a convinient way to plot distributions for different categories. Let's plot the logarithim of the tripduration for each day and the two genders.\n",
    "\n",
    "(To show the histograms, we are going to use the [kernel density estimate](https://en.wikipedia.org/wiki/Kernel_density_estimation) plot of seaborn, which is basically a smoothed version of the raw histogram.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(trips, col='dayofweek', hue='gender', col_wrap=4) #specify the grid\n",
    "g.map(sns.kdeplot, 'logduration') #specify the type of plot, here: kernel density estimate\n",
    "g.add_legend(); #add legend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seaborn can handle many types of plots that we don't have time to cover in the class. [Click here to explore](https://seaborn.pydata.org/examples/index.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding station data\n",
    "\n",
    "Recall that we also have information about stations in 'Divvy_Stations_2013.csv'. Let's have a look at this data and add it to our trips dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations = pd.read_csv('Divvy_Stations_2013.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations[['name','latitude','longitude']].loc[(stations['name'] == \"Michigan Ave & Oak St\") | (stations['name'] == \"Racine Ave & Congress Pkwy\")| (stations['name'] == \"Loomis St & Taylor St\")].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trips[['trip_id',\"starttime\",\"from_station_name\",\"to_station_name\"]].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(stations))\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a much smaller dataframe with totally different rows. We want to join the stations dataframe to the trips dataframe so that we have lat/long/capacity data for each trips' starting and ending stations. The name column in the stations frame corresponds to the `from_station_name` and `to_station_name columns` in the trip frame. For this task we can use the [merge()](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.merge.html) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Video](https://ceu.cloud.panopto.eu/Panopto/Pages/Viewer.aspx?id=b3628637-bd80-47f6-8225-ab8b00dd9d62)\n",
    "\n",
    "First, merge trips and stations for the starting stations. Let's unpack the following function call:\n",
    "* `merge()` takes two dataframes `left` and `right`\n",
    "* `how='left'` means that we take the `left` dataframe, in this case `trips`, and we add new columns to it based on the `right` dataframe, in this case `stations`. Therefore in the new dataframe we will have the same number of rows as in `trips`.\n",
    "* `left_on='from_station_name'` and `right_on='name'`: `merge()` takes a rew in `left` looks at the `from_station_name` and looks for a match in the `right` dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trips2 = pd.merge(left=trips, right=stations, how='left', left_on='from_station_name', right_on='name')\n",
    "\n",
    "trips2[['trip_id',\"starttime\",\"from_station_name\",\"to_station_name\",'latitude','longitude']].head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataframe that contains the trips + information about the starting station. For example, the `lattitude` column contains the lattitude of the starting station.\n",
    "\n",
    "We also want to add the information about the destination stations. If we do the same as before, we would get duplicate column names, e.g., two `lattitude` columns. To avoid this `merge()` can add a suffix to the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#added a suffix list for duplicated names\n",
    "trips_extended = pd.merge(trips2, stations, how='inner', left_on='to_station_name', right_on='name',\n",
    "                    suffixes=['_origin', '_dest'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check the first three rows of the new dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trips_extended.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a bunch of new data to work with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "What are the most popular routes? Create a dataframe called `station_to_station` that has a row for each station origin-destination pair and has columns:\n",
    "* `from_station_name`\n",
    "* `to_station_name`\n",
    "* And a column containing the total number of trips between the two stations. (Bonus: rename this column `numtrips`.)\n",
    "* Print out the top 10 station pairs\n",
    "\n",
    "<details><summary><u>Hint 1.</u></summary>\n",
    "<p>\n",
    "\n",
    "Group `trips_extended` by two columns: `'from_station_name'` and `'to_station_name'`.\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary><u>Hint 2.</u></summary>\n",
    "<p>\n",
    "\n",
    "To aggregate the data for each group use `count()`.\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "\n",
    "<details><summary><u>Hint 3.</u></summary>\n",
    "<p>\n",
    "\n",
    "You can rename columns using `df.rename(columns = {'old_col_name':'new_col_name'},inplace=True)`. For details look up the documentation!\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "station_to_station = trips_extended.groupby(['from_station_name','to_station_name'])['trip_id'].count().reset_index()\n",
    "station_to_station.rename(columns = {'trip_id':'numtrips'},inplace=True)\n",
    "station_to_station.sort_values('numtrips', ascending=False).head()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Network of stations\n",
    "\n",
    "We don't have to restrict ourselves to analyzing the data with pandas. The `station_to_station` dataframe can be thought of as a weighted directed edge list. Let's build a network out of it and plot it!\n",
    "\n",
    "How many nodes and edges are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of nodes:\", len(stations))\n",
    "print(\"Number of edges:\", len(station_to_station))\n",
    "print(\"Maximum number of possible directed edges:\", len(stations)*len(stations))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost half of all possible edges are present, this is too dense for normal network analysis. Let's threshold the edges and only include the most possible routes, i.e., the station pairs that have more than `T` trips.\n",
    "\n",
    "Let's filter the `station_to_station` dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "T = 150\n",
    "\n",
    "filtered_station_to_station = station_to_station[station_to_station['numtrips']>T]\n",
    "print(len(filtered_station_to_station))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's create a networkx network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "g = nx.DiGraph()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add edges using `g.add_edges_from(edgelist)`, where `edgelist` is an iterable containing `(src,dest)` tuples representing the edges. We can create a series like this using `apply()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edgelist = filtered_station_to_station.apply(lambda row: (row['from_station_name'],row['to_station_name']),axis=1)\n",
    "edgelist.head()\n",
    "\n",
    "g.add_edges_from(edgelist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot this network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos = nx.kamada_kawai_layout(g)\n",
    "plt.figure(figsize=(10,5))\n",
    "nx.draw_networkx_nodes(g, pos, node_size=50, node_color=\"#00aaaa\") #draw nodes\n",
    "nx.draw_networkx_edges(g, pos, edgelist=g.edges()) #draw edges\n",
    "\n",
    "plt.axis('off');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We stop here, but the interested reader could further analyse the network, e.g., look at different centralites or community structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hours of day\n",
    "\n",
    "Using the `hour` attribute of the timestamp objects, create a new column that contains the hour of the day when the trip started. Plot the average trip duration and/or total number of trips that happened in each hour with a separate color for each day of the week using seaborn.\n",
    "\n",
    "Can you explain the patterns that you see?\n",
    "\n",
    "<details><summary><u>Hint 1</u></summary>\n",
    "<p>\n",
    "\n",
    "Creating the new column: This is very similar to what we did with the day of week, only instead of using `dt.dayofweek`, we have to use `dt.hour`.\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary><u>Hint 2</u></summary>\n",
    "<p>\n",
    "\n",
    "Plotting: This is very similar to what we did with the `dayofweek` and `gender`, only instead of using `gender` use the new column. Make sure that the hue represents the days of the week and the x axis represents the hour of the day.\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "trips['hour']=trips['starttime'].apply(lambda dt: dt.hour)\n",
    "\n",
    "dayofweek_usertype_duration = trips.groupby(['dayofweek','hour'])['tripduration'].count().reset_index()\n",
    "ax=sns.pointplot(data=dayofweek_usertype_duration,x='hour',y='tripduration', hue='dayofweek')\n",
    "ax.set_ylabel('Number of trips')\n",
    "ax.set_title('Number of trips per user type');\n",
    "sns.despine()\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capacity\n",
    "\n",
    "Investigate the relationship between station capacity and traffic. Which two stations would you expand if you had the budget?\n",
    "* Create a series indexed by the station name and containing the total number of out-going traffic of each station\n",
    "* Do the same thing with out-traffic and add the two series together to get the total traffic\n",
    "* Use `merge()` to add traffic data to the `stations` dataframe\n",
    "* Create a scatter plot showing the correlation between traffic and capacity\n",
    "\n",
    "<details><summary><u>Hint 1</u></summary>\n",
    "<p>\n",
    "\n",
    "To get the out-traffic group the trips by `from_station_name` and use `count()` on the `trip_id` column.\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary><u>Hint 2</u></summary>\n",
    "<p>\n",
    "\n",
    "Use `merge()` very similarly as we did earlier to extend the `trips` dataframe. Try renaming the new column!\n",
    "The next hint reveals the exact code to do the merge.\n",
    "\n",
    "</p>\n",
    "</details>\n",
    "\n",
    "<details><summary><u>Hint 3</u></summary>\n",
    "<p>\n",
    "\n",
    "```python\n",
    "stations_extended = pd.merge(left=stations, right=traffic, how='left', left_on='name', right_on='to_station_name')\n",
    "```\n",
    "The series object has a name attribute, in this case `traffic.name`, that will become the name of the column after the merge. You can rename the column after the merge, or you can change the name of the series before the merge.\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "outtraffic = trips_extended.groupby('from_station_name')['trip_id'].count()\n",
    "intraffic = trips_extended.groupby('to_station_name')['trip_id'].count()\n",
    "traffic = intraffic+outtraffic\n",
    "traffic.name = \"traffic\"\n",
    "stations_extended = pd.merge(left=stations, right=traffic, how='left', left_on='name', right_on='to_station_name')\n",
    "stations_extended.plot(kind='scatter',x='dpcapacity',y='traffic');\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources and sinks\n",
    "\n",
    "Which stations are sources and which stations are sinks, i.e. which stations have much more departures than arrivals, and vice versa? Print out the top 10 stations with the largest in- and out-traffic difference.\n",
    "\n",
    "<details><summary><u>Hint.</u></summary>\n",
    "<p>\n",
    "\n",
    "Use the part of the solution of the previous exercise.\n",
    "\n",
    "To sort a series `S` by its values use `S.sort_values()`.\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details><summary><u>Solution.</u></summary>\n",
    "<p>\n",
    "    \n",
    "```python\n",
    "traffic_diff = np.abs(intraffic-outtraffic).sort_values(ascending=False)\n",
    "traffic_diff.head(10)\n",
    "```\n",
    "    \n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final exercise\n",
    "\n",
    "Pick **one** of the following problems and create a figure. Upload only a **single figure as a pdf** to Moodle, do not upload your code. Successfully completing this task counts as attendance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Distances\n",
    "\n",
    "Let's pull up our old favorite, the [haversine formula](https://en.wikipedia.org/wiki/Haversine_formula)! It converts lattitude and longitude to distance (in this case, kilometers):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def latlongdist(lat1,long1,lat2,long2):\n",
    "    rlat1 = math.radians(lat1)\n",
    "    rlat2 = math.radians(lat2)\n",
    "    rlong1 = math.radians(long1)\n",
    "    rlong2 = math.radians(long2)\n",
    "    dlat = rlat2 - rlat1\n",
    "    dlong = rlong2 - rlong1\n",
    "    a = math.sin(dlat / 2)**2 + math.cos(rlat1) * math.cos(rlat2) * math.sin(dlong / 2)**2\n",
    "    c = 2 * math.atan2(math.sqrt(a), math.sqrt(1 - a))\n",
    "    return 6371.0 * c\n",
    "\n",
    "print(latlongdist(48.105625, 20.790556, 46.07308, 18.22857))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this formula to add a new column to the `trips_extended` dataframe that contains the distance (as the crow flies) between the origin and destination stations. Then create a figure to answer one of the following questions:\n",
    "* Does the trip duration and distance correlate?\n",
    "* Do men or women go on longer trips?\n",
    "* How does the trip distance depend on the day of the week?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Age\n",
    "\n",
    "Using the `birthday` column in `trips` calculate the age of the rider in years and create a new column `age`. Then answer one of these questions:\n",
    "* What is the age distribution of riders depending on their gender?\n",
    "* Does the trip duration depend on age?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Other\n",
    "\n",
    "Come up with an interesting plot using this data set."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
